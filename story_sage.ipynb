{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --no-cache-dir jupyter langchain_openai langchain_community langchain langgraph faiss-cpu sentence-transformers ipywidgets transformers nltk scikit-learn matplotlib markdown langchain_chroma\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "import faiss\n",
    "from langchain import hub, PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import yaml\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import httpx\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import markdown\n",
    "import glob\n",
    "import re\n",
    "import chromadb\n",
    "\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "from story_sage import StorySage, StorySageGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS backend available\n",
      "Loaded character dictionary\n"
     ]
    }
   ],
   "source": [
    "with open('config.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = config['OPENAI_API_KEY']\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('MPS backend available')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('MPS backend not available. Using CPU')\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', http_client = httpx.Client(verify=False))\n",
    "#tokenizer = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
    "tokenizer = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "tokenizer = tokenizer.to(device)\n",
    "\n",
    "\n",
    "with open('merged_characters.pkl', 'rb') as f:\n",
    "    character_dict = pickle.load(f)\n",
    "print('Loaded character dictionary')\n",
    "\n",
    "class Embedder(EmbeddingFunction):\n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "      self.model = SentenceTransformer(model_name)\n",
    "      self.model = self.model.to(device)\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "       return self.model.encode(input).tolist()\n",
    "    \n",
    "    def embed_documents(self, documents: Documents) -> Embeddings:\n",
    "       embedded_documents = []\n",
    "       for document in tqdm(documents, desc='Embedding documents'):\n",
    "          embedded_document = self.model.encode(document)\n",
    "          embedded_documents.append(embedded_document)\n",
    "       return embedded_documents\n",
    "  \n",
    "embedder = Embedder()\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path='./chroma_data')\n",
    "\n",
    "vector_store = chroma_client.get_collection(\n",
    "     name=\"wheel_of_time\",\n",
    "     embedding_function=embedder\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=['question', 'context'],\n",
    "    template=\"\"\"\n",
    "HUMAN\n",
    "\n",
    "You are an assistant to help a reader keep track of people, places, and plot points in books.\n",
    "The following pieces of retrieved context are excerpts from the books related to the reader's question. Use them to generate your response.\n",
    "\n",
    "Guidelines for the response:\n",
    "* If you don't know the answer, just say that you don't know. \n",
    "* If you're not sure about something, you can say that you're not sure.\n",
    "* Take as much time as you need to answer the question.\n",
    "* Use as many words as you need to answer the question completely, but don't provide any irrelevant information.\n",
    "* Use bullet points to provide examples from the context that support your answer.\n",
    "\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def retrieve_chunks(query, vector_store: chromadb.Collection, book_number, chapter_number, characters=[], top_k=10):\n",
    "    \n",
    "    book_chapter_filter = {\n",
    "        '$or': [\n",
    "            {'book_number': {'$lt': book_number}},\n",
    "            {'$and': [\n",
    "                {'book_number': book_number},\n",
    "                {'chapter_number': {'$lt': chapter_number}}\n",
    "            ]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    if characters:\n",
    "        characters_filter = []\n",
    "        for character in characters:\n",
    "            characters_filter.append({f'character_{character}': True})\n",
    "        if len(characters_filter) == 1:\n",
    "            characters_filter = characters_filter[0]\n",
    "        else:\n",
    "            characters_filter = {'$or': characters_filter}\n",
    "        query_filter = {\n",
    "            '$and': [\n",
    "                characters_filter,\n",
    "                book_chapter_filter\n",
    "            ]\n",
    "        }\n",
    "    else:\n",
    "        query_filter = book_chapter_filter\n",
    "\n",
    "\n",
    "    \n",
    "    chunks = vector_store.query(\n",
    "        query_texts=[query],\n",
    "        n_results=top_k,\n",
    "        include=['metadatas', 'documents'],\n",
    "        where=query_filter\n",
    "    )\n",
    "    # D, I = index.search(np.array(query_embedding), 20)\n",
    "    # relevant_chunks = [\n",
    "    #     doc_collection[i] for i in I[0]\n",
    "    #     if int(index_metadata[i]['book_number']) < book_number or\n",
    "    #        (int(index_metadata[i]['book_number'] == book_number and index_metadata[i]['chapter_number'] < chapter_number))\n",
    "    # ]\n",
    "    # sort relevant_chunks by book_number and chapter_number in descending order\n",
    "    #relevant_chunks = sorted(relevant_chunks, key=lambda x: (x.metadata['book_number'], x.metadata['chapter_number']), reverse=True)\n",
    "    #print('retrieved chunks:', len(relevant_chunks))\n",
    "    #return relevant_chunks[:top_k]\n",
    "    return chunks\n",
    "\n",
    "def retrieve_chunks_from_chroma(query, vector_store: chromadb.Collection, book_number, chapter_number, top_k=10):\n",
    "    query_embedding = tokenizer.encode([query])\n",
    "    results = vector_store.query(\n",
    "        query_embedding=query_embedding,\n",
    "        n_results=top_k,\n",
    "        include='metadatas'\n",
    "    )\n",
    "    return results\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[str]\n",
    "    answer: str\n",
    "    book_number: int\n",
    "    chapter_number: int\n",
    "    top_k: int\n",
    "    characters: List[int]\n",
    "\n",
    "def get_characters(state: State):\n",
    "    print('get characters in question')\n",
    "    characters_in_question = set()\n",
    "    for character in character_dict.keys():\n",
    "        if str.lower(character) in str.lower(state['question']):\n",
    "            characters_in_question.add(character_dict[character])\n",
    "    print(f'characters in question: {list(characters_in_question)}')\n",
    "    return {'characters': list(characters_in_question)}\n",
    "\n",
    "def retrieve(state: State):\n",
    "    print('retrieve')\n",
    "    print(state)\n",
    "    retrieved_docs = retrieve_chunks(state['question'], vector_store, state['book_number'], state['chapter_number'], state['characters'], state['top_k'])\n",
    "    return {'context': retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc for doc in state['context']['documents'][0])\n",
    "    print(f'begin generation with {len(docs_content)} characters of context')\n",
    "    messages = prompt.invoke({'question': state['question'], 'context': docs_content})\n",
    "    print('generated message:', messages)\n",
    "    response = llm.invoke(messages)\n",
    "    return {'answer': response.content}\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([get_characters, retrieve, generate])\n",
    "graph_builder.add_edge(START, 'get_characters')\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6301decd9214e16834134798590de79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc01d4b00c146ee93aa38ca6ac2d9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(min_height='50px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9a60810dc94404ba170e77f6dd1ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=10, description='Book Number:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f204acbfca4bd6b9785e604f320ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=0, description='Chapter Number:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bcddff01284508b13f189a6f143a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=25, description='Top K:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5447692fb94d19acdb9e4fc3ce289d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', continuous_update=False, description='Question:', placeholder='Type your question here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297152a512c94e738619cf443b414a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', icon='check', style=ButtonStyle(), tooltip='Click to submit your question')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa1687864a64eadabb80c7d275e4744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(min_height='200px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bc0095773641faa661a049d0c54d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(min_height='200px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the input and output widgets\n",
    "input_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your question here...',\n",
    "    description='Question:',\n",
    "    continuous_update=False,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "submit_button = widgets.Button(\n",
    "    description='Submit',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Click to submit your question',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "book_number_box = widgets.IntText(\n",
    "    value=10,\n",
    "    description='Book Number:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "chapter_number_box = widgets.IntText(\n",
    "    value=None,\n",
    "    description='Chapter Number:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "top_k_box = widgets.IntText(\n",
    "    value=25,\n",
    "    description='Top K:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "status_box = widgets.Output(layout={'min_height': '50px'})\n",
    "output_box = widgets.Output(layout={'min_height': '200px'})\n",
    "context_box = widgets.Output(layout={'min_height': '200px'})\n",
    "\n",
    "# Create a spinner widget\n",
    "spinner = widgets.HTML(\n",
    "    value=\"\"\"<i class=\"fa fa-spinner fa-spin\" style=\"font-size:24px; color:#2a9df4;\"></i>\"\"\",\n",
    "    placeholder='Loading...',\n",
    "    description=''\n",
    ")\n",
    "\n",
    "# Make sure Font Awesome is available\n",
    "display(widgets.HTML(\"<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css'>\"))\n",
    "\n",
    "def wrap_answer(answer):\n",
    "    html = markdown.markdown(answer)\n",
    "    return f\"<div style='background-color: #f9f9f9; padding: 10px; border-radius: 5px;'>{html}</div>\"\n",
    "\n",
    "def show_results(state):\n",
    "    with output_box:\n",
    "        output_box.clear_output()\n",
    "        output_box_contents = []\n",
    "        output_box_contents.append(\"<h3>Answer</h3>\")\n",
    "        output_box_contents.append(wrap_answer(state['answer']))\n",
    "        display(widgets.HTML(''.join(output_box_contents)))\n",
    "        with context_box:\n",
    "            context_box.clear_output()\n",
    "            context_box_contents = []\n",
    "            context_box_contents.append(\"<h3>Context</h3>\")\n",
    "            for idx in range(len(state['context']['metadatas'])):\n",
    "                meta = state['context']['metadatas'][0][idx]\n",
    "                content = state['context']['documents'][0][idx]\n",
    "                context_box_contents.append(f\"<p><strong>Book Number:</strong> {meta['book_number']} <strong>Chapter Number:</strong> {meta['chapter_number']}</p>\")\n",
    "                context_box_contents.append(f\"<p>{content}</p>\")\n",
    "            display(widgets.HTML(wrap_answer(\"\".join(context_box_contents))))\n",
    "\n",
    "def send_query(state):\n",
    "    result = graph.invoke(state)\n",
    "    state['answer'] = result['answer']\n",
    "    state['context'] = result['context']\n",
    "    show_results(state)\n",
    "    \n",
    "\n",
    "# Define the function to handle the button click\n",
    "def submit_question(b):\n",
    "    top_k = top_k_box.value\n",
    "    with status_box:\n",
    "        status_box.clear_output()\n",
    "        display(widgets.HTML(f\"<h3>Retrieving top {top_k} relevant chunks...</h3>\"))\n",
    "        with output_box:\n",
    "            output_box.clear_output()\n",
    "            display(spinner)\n",
    "\n",
    "            state = State(\n",
    "                question=input_box.value,\n",
    "                book_number=book_number_box.value or 1,\n",
    "                chapter_number=chapter_number_box.value or 0,\n",
    "                top_k=top_k_box.value or 10,\n",
    "                context=[],\n",
    "                references=[],\n",
    "                answer=''\n",
    "            )\n",
    "            send_query(state)\n",
    "\n",
    "# Attach the handler to the button\n",
    "submit_button._click_handlers.callbacks.clear()\n",
    "submit_button.on_click(submit_question)\n",
    "\n",
    "# Attach the handler to the input box for the return key\n",
    "input_box.observe(submit_question)\n",
    "\n",
    "# Display the widgets\n",
    "display(status_box, book_number_box, chapter_number_box, top_k_box, input_box, submit_button, output_box, context_box)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "story_sage_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
