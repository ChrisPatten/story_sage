{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/story_sage/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/opt/anaconda3/envs/story_sage/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS, InMemoryVectorStore\n",
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "with open('config.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = config['OPENAI_API_KEY']\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "tokenizer = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_the_eye_of_the_world.txt\n",
      "06_lord_of_chaos.txt\n",
      "07_crown_of_swords.txt\n",
      "09_winters_heart.txt\n",
      "03_the_dragon_reborn.txt\n",
      "05_fires_of_heaven.txt\n",
      "04_shadow_rising.txt\n",
      "02_the_great_hunt.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from collections import OrderedDict\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    text_dict = OrderedDict()\n",
    "    for file in glob.glob(file_path):\n",
    "        fname = os.path.basename(file)\n",
    "        print(fname)\n",
    "        with open(file, 'r') as f:\n",
    "            text_dict[fname] = f.read()\n",
    "    return text_dict\n",
    "\n",
    "file_path = './books/*.txt'\n",
    "text_dict = read_text_file(file_path)\n",
    "all_text = \"\\n\".join(text_dict.values())\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_text(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = tokenizer.encode(all_splits)\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/story_sage/lib/python3.12/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "\n",
    "def retrieve_chunks(query, index, top_k=5):\n",
    "    query_embedding = tokenizer.encode([query])\n",
    "    D, I = index.search(np.array(query_embedding), top_k)\n",
    "    relevant_chunks = [all_splits[i] for i in I[0]]\n",
    "    return relevant_chunks\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[str]\n",
    "    answer: str\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = retrieve_chunks(state['question'], index)\n",
    "    return {'context': retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(text for text in state['context'])\n",
    "    messages = prompt.invoke({'question': state['question'], 'context': docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {'answer': response.content}\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, 'retrieve')\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba3317ec2524054bfcbede401787284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', continuous_update=False, description='Question:', placeholder='Type your question here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c97b5e5adc341b18d89b3ac3063c171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', icon='check', style=ButtonStyle(), tooltip='Click to submit your question')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89b6f68093f48f6886e949b757fe0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define the input and output widgets\n",
    "input_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your question here...',\n",
    "    description='Question:',\n",
    "    continuous_update=False,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "submit_button = widgets.Button(\n",
    "    description='Submit',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Click to submit your question',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "output_box = widgets.Output()\n",
    "\n",
    "# Define the function to handle the button click\n",
    "def submit_question(b):\n",
    "    with output_box:\n",
    "        output_box.clear_output()\n",
    "        state = State(question=input_box.value, context=[], answer='')\n",
    "        result = graph.invoke(state)\n",
    "        wrapped_answer = f\"<div style='background-color: #f9f9f9; padding: 10px; border-radius: 5px;'>{result['answer']}</div>\"\n",
    "        display(widgets.HTML(wrapped_answer))\n",
    "\n",
    "# Attach the handler to the button\n",
    "submit_button.on_click(submit_question)\n",
    "\n",
    "# Attach the handler to the input box for the return key\n",
    "input_box.observe(submit_question)\n",
    "\n",
    "# Display the widgets\n",
    "display(input_box, submit_button, output_box)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "story_sage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
